import time
import os
import torch
import numpy as np
import csv
import sys
import nibabel as nib  # [æ–°å¢] ç”¨äºè¯»å–å›ºå®šçš„ NIfTI ç›‘æ§æ–‡ä»¶
from tqdm import tqdm
from options.train_options import TrainOptions
from data import create_dataset
from models import create_model

# === å¼•å…¥ Matplotlib ===
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# =========================================================================
# è¾…åŠ©å‡½æ•°ï¼šTensorè½¬å›¾ (è‡ªåŠ¨å¤„ç† 3D åˆ‡ç‰‡)
# =========================================================================
def tensor2im_custom(input_image, imtype=np.uint8):
    if not isinstance(input_image, torch.Tensor):
        return input_image
    
    image_tensor = input_image.data
    image_numpy = image_tensor[0].cpu().float().numpy() 
    
    if image_numpy.ndim == 4:
        mid_slice = image_numpy.shape[1] // 2
        image_numpy = image_numpy[:, mid_slice, :, :]
        
    if image_numpy.shape[0] == 1:
        image_numpy = np.tile(image_numpy, (3, 1, 1))
        
    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0
    image_numpy = np.clip(image_numpy, 0, 255).astype(imtype)
    
    return image_numpy

def calculate_psnr(img1, img2):
    mse = np.mean((img1.astype(np.float32) - img2.astype(np.float32)) ** 2)
    if mse == 0: return 100
    return 20 * np.log10(255.0 / np.sqrt(mse))

# =========================================================================
# [æ ¸å¿ƒåŠŸèƒ½] ç»˜åˆ¶è®ºæ–‡çº§ç›‘æ§å›¾
# =========================================================================
def save_paper_style_fig(save_path, epoch, exp_name, psnr_val, img_lq, img_fake, img_sq):
    fig, axes = plt.subplots(1, 3, figsize=(18, 6.5))
    
    header_txt = f"Exp: {exp_name}  |  Epoch: {epoch}  |  Fixed Sample PSNR: {psnr_val:.2f} dB"
    fig.suptitle(header_txt, fontsize=20, fontweight='bold', y=0.92)
    
    items = [
        ('Input (Low Quality)', img_lq),
        ('Generated (High Quality)', img_fake),
        ('Ground Truth (High Quality)', img_sq)
    ]
    
    for ax, (title, img) in zip(axes, items):
        ax.imshow(img)
        ax.set_title(title, fontsize=16, pad=10, fontweight='medium')
        ax.axis('off') 
    
    plt.subplots_adjust(top=0.85, wspace=0.05, left=0.02, right=0.98, bottom=0.02)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

# =========================================================================
# ä¸»è®­ç»ƒé€»è¾‘
# =========================================================================
if __name__ == '__main__':
    opt = TrainOptions().parse()
    
    print("\n" + "="*80)
    print(f"ğŸš€ è®­ç»ƒå¯åŠ¨ | å®éªŒ: {opt.name}")
    print(f"ğŸ“‚ æ•°æ®è·¯å¾„: {opt.dataroot}")
    print("="*80 + "\n")

    dataset = create_dataset(opt)
    dataset_size = len(dataset) * opt.batch_size 
    
    model = create_model(opt)
    model.setup(opt)
    
    # =========================================================================
    # [æ ¸å¿ƒä¿®æ”¹ 1]ï¼šåœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œé¢„å…ˆåŠ è½½æˆ‘ä»¬åšå¥½çš„â€œå®šç‚¹ç›‘æ§æ ·æœ¬â€
    # =========================================================================
    monitor_lq_path = './monitor_data/monitor_LQ.nii'
    monitor_hq_path = './monitor_data/monitor_HQ.nii'
    
    has_monitor = os.path.exists(monitor_lq_path) and os.path.exists(monitor_hq_path)
    mon_lq_tensor, mon_hq_tensor = None, None
    

    if has_monitor:
        print("ğŸ” å‘ç°å›ºå®šç›‘æ§æ ·æœ¬ï¼Œæ­£åœ¨åŠ è½½...")
        # è¯»å– NIfTI æ•°æ®å¹¶è½¬ä¸º float32
        mon_lq_np = nib.load(monitor_lq_path).get_fdata().astype(np.float32)
        mon_hq_np = nib.load(monitor_hq_path).get_fdata().astype(np.float32)
        
        # ==========================================================
        # [å½’ä¸€åŒ–é€»è¾‘]ï¼šæ˜ å°„åˆ° [-1, 1]
        # ==========================================================
        norm_min = getattr(opt, 'norm_min', -60.0)
        norm_max = getattr(opt, 'norm_max', 0.0)
        
        mon_lq_np = (mon_lq_np - norm_min) / (norm_max - norm_min)
        mon_hq_np = (mon_hq_np - norm_min) / (norm_max - norm_min)
        mon_lq_np = mon_lq_np * 2.0 - 1.0
        mon_hq_np = mon_hq_np * 2.0 - 1.0
        mon_lq_np = np.clip(mon_lq_np, -1.0, 1.0)
        mon_hq_np = np.clip(mon_hq_np, -1.0, 1.0)
        
        # ==========================================================
        # [æ ¸å¿ƒä¿®å¤ï¼š2.5D é™ç»´æ”¹é€ ]ï¼šæå–ä¸­å¿ƒå±‚ï¼ŒæŠ›å¼ƒ 3D ä½“ç§¯
        # ==========================================================
        # å‡è®¾ mon_lq_np å½¢çŠ¶æ˜¯ (D, H, W)ï¼Œæ¯”å¦‚ (128, 64, 64)
        d, h, w = mon_lq_np.shape
        z = d // 2  # å–æœ€ä¸­é—´çš„ä¸€å±‚ä½œä¸ºå›ºå®šç›‘æ§åˆ‡ç‰‡
        z_prev = max(0, z - 1)
        z_next = min(d - 1, z + 1)
        
        # ä¸º LQ åˆ‡å‡º 3 å±‚
        lq_slice_prev = mon_lq_np[z_prev, :, :]
        lq_slice_curr = mon_lq_np[z, :, :]
        lq_slice_next = mon_lq_np[z_next, :, :]
        
        # å æˆ (3, H, W) å’Œ (1, H, W)
        mon_lq_25d = np.stack([lq_slice_prev, lq_slice_curr, lq_slice_next], axis=0)
        mon_hq_2d = np.expand_dims(mon_hq_np[z, :, :], axis=0)
        
        # å‡ç»´åŠ ä¸Š Batch ç»´åº¦: (1, Channel, H, W)
        mon_lq_tensor = torch.from_numpy(mon_lq_25d).unsqueeze(0).to(model.device)
        mon_hq_tensor = torch.from_numpy(mon_hq_2d).unsqueeze(0).to(model.device)
        
        print(f"âœ… å›ºå®šç›‘æ§æ ·æœ¬å·²è½¬æ¢ä¸º 2.5Dï¼LQ={mon_lq_tensor.shape}, HQ={mon_hq_tensor.shape}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ° monitor_dataï¼Œè¯·ç¡®è®¤ä½ æ˜¯å¦è¿è¡Œè¿‡ crop_monitor_patch.pyï¼")
        
    expr_dir = os.path.join(opt.checkpoints_dir, opt.name)
    if not os.path.exists(expr_dir): os.makedirs(expr_dir)
    log_name = os.path.join(expr_dir, 'loss_log.csv')
    loss_names = model.loss_names 
    
    if not opt.continue_train or not os.path.exists(log_name):
        with open(log_name, mode='w', newline='') as f:
            header = ['Epoch', 'Time(s)'] + loss_names + ['Train_PSNR', 'LR']
            csv.writer(f).writerow(header)

    total_iters = 0                 
    for epoch in range(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + 1):
        epoch_start_time = time.time()
        
        epoch_loss_sum = {name: 0.0 for name in loss_names}
        epoch_psnr_sum = 0.0
        num_batches = 0

        pbar = tqdm(enumerate(dataset), total=len(dataset), desc=f"Epoch {epoch}", file=sys.stdout)

        for i, data in pbar:
            iter_start_time = time.time()
            total_iters += opt.batch_size
            
            model.set_input(data)
            model.optimize_parameters()
            
            errors = model.get_current_losses()
            for k, v in errors.items():
                if k in epoch_loss_sum: epoch_loss_sum[k] += v

            # è®¡ç®—è®­ç»ƒé›†çš„å¹³å‡ PSNR ç”¨äºè¿›åº¦æ¡æ˜¾ç¤º
            fake_tensor = getattr(model, 'fake_sq', None)
            real_tensor = getattr(model, 'real_sq', None)
            
            current_psnr = 0.0
            if fake_tensor is not None and real_tensor is not None:
                fake_im_raw = tensor2im_custom(fake_tensor)
                real_im_raw = tensor2im_custom(real_tensor)
                current_psnr = calculate_psnr(fake_im_raw, real_im_raw)
                epoch_psnr_sum += current_psnr

            num_batches += 1

            pbar.set_postfix({
                'L1': f"{errors.get('G_L1', errors.get('G_Pixel', 0)):.3f}", 
                'PSNR': f"{current_psnr:.1f}"
            })

            if total_iters % opt.save_latest_freq == 0:
                model.save_networks('latest')

        # === Epoch ç»“æŸç»“ç®— ===
        if num_batches > 0:
            for k in epoch_loss_sum: epoch_loss_sum[k] /= num_batches
            avg_psnr = epoch_psnr_sum / num_batches
        else:
            avg_psnr = 0.0
        
        time_taken = time.time() - epoch_start_time
        model.update_learning_rate()
        current_lr = model.optimizers[0].param_groups[0]['lr']

        # 1. æ‰“å°ä»ªè¡¨ç›˜ Log
        gen_losses = []
        disc_losses = []
        for k, v in epoch_loss_sum.items():
            if k.startswith('G_'):
                gen_losses.append(f"{k.replace('G_', '')}: {v:.4f}")
            elif k.startswith('D_'):
                disc_losses.append(f"{k.replace('D_', '')}: {v:.4f}")

        log_msg = (
            f"\n{'='*20} Epoch {epoch} Summary {'='*20}\n"
            f"  ğŸ¨ [Generator Avg] |  {'  |  '.join(gen_losses)}\n"
            f"  âš–ï¸  [Discriminator] |  {'  |  '.join(disc_losses)}\n"
            f"  ğŸ“Š [Metrics Avg]   |  Train PSNR: {avg_psnr:.2f} dB  |  Time: {time_taken:.1f}s  |  LR: {current_lr:.6f}\n"
            f"{'-'*60}\n"
        )
        print(log_msg)

        # 2. å†™å…¥ CSV
        with open(log_name, mode='a', newline='') as f:
            row = [epoch, f"{time_taken:.1f}"]
            for name in loss_names:
                row.append(f"{epoch_loss_sum.get(name, 0.0):.4f}")
            row.append(f"{avg_psnr:.2f}")
            row.append(f"{current_lr:.6f}")
            csv.writer(f).writerow(row)

        # =========================================================================
        # [æ ¸å¿ƒä¿®æ”¹ 2]ï¼šåœ¨æ¯ä¸ª Epoch ç»“æŸæ—¶ï¼Œå°†å›ºå®šæ ·æœ¬å–‚ç»™æ¨¡å‹ï¼Œå¹¶ä¿å­˜ç›‘æ§å›¾
        # =========================================================================
        if has_monitor:
            img_dir = os.path.join(expr_dir, 'web_images')
            if not os.path.exists(img_dir): os.makedirs(img_dir)
            
            # å¼€å¯ eval æ¨¡å¼ï¼Œå…³é—­æ¢¯åº¦ï¼Œè¿™èƒ½ä¿è¯è¿™æ¬¡æ¨ç†ç»å¯¹ä¸æ±¡æŸ“è®­ç»ƒè¿›åº¦
            model.netG.eval()
            with torch.no_grad():
                mon_fake_tensor = model.netG(mon_lq_tensor)
            model.netG.train() # æ¨ç†å®Œç«‹åˆ»åˆ‡å›è®­ç»ƒæ¨¡å¼ï¼
            
            # è½¬ä¸º numpy å›¾ç‰‡æ ¼å¼
            img_lq = tensor2im_custom(mon_lq_tensor)
            img_fake = tensor2im_custom(mon_fake_tensor)
            img_sq = tensor2im_custom(mon_hq_tensor)
            
            # è®¡ç®—ä¸“é—¨é’ˆå¯¹è¿™å¼ ç¥ä»™å›¾çš„ PSNR
            slice_psnr = calculate_psnr(img_fake, img_sq)
            
            # ä¿å­˜é›·æ‰“ä¸åŠ¨çš„å®šç‚¹å›¾
            save_path = os.path.join(img_dir, f'epoch_{epoch:03d}_comparison.png')
            save_paper_style_fig(save_path, epoch, opt.name, slice_psnr, img_lq, img_fake, img_sq)

        # 4. ä¿å­˜æ¨¡å‹
        if epoch % opt.save_epoch_freq == 0:
            model.save_networks('latest')
            model.save_networks(epoch)

    print("ğŸ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")

# import time
# import os
# import torch
# import numpy as np
# import csv
# import sys
# from tqdm import tqdm
# from options.train_options import TrainOptions
# from data import create_dataset
# from models import create_model

# # === [å¼•å…¥ Matplotlib] ===
# import matplotlib
# matplotlib.use('Agg') # ç¡®ä¿åœ¨æ— å±å¹•æœåŠ¡å™¨ä¸Šä¹Ÿèƒ½è¿è¡Œ
# import matplotlib.pyplot as plt

# # =========================================================================
# # è¾…åŠ©å‡½æ•°ï¼šTensorè½¬å›¾ (è‡ªåŠ¨å¤„ç† 3D åˆ‡ç‰‡)
# # =========================================================================
# def tensor2im_custom(input_image, imtype=np.uint8):
#     """
#     å°† Tensor è½¬æ¢ä¸º Numpy å›¾åƒï¼Œè‡ªåŠ¨å¤„ç† 3D æ•°æ®çš„ä¸­é—´åˆ‡ç‰‡
#     """
#     if not isinstance(input_image, torch.Tensor):
#         return input_image
    
#     image_tensor = input_image.data
#     image_numpy = image_tensor[0].cpu().float().numpy() # å– Batch ç¬¬ä¸€ä¸ª -> (C, D, H, W) æˆ– (C, H, W)
    
#     # [æ ¸å¿ƒé€‚é…] 3D -> 2D åˆ‡ç‰‡
#     # å¦‚æœç»´åº¦æ˜¯ 4 (C, D, H, W)ï¼Œè¯´æ˜æ˜¯ 3D æ•°æ®
#     if image_numpy.ndim == 4:
#         mid_slice = image_numpy.shape[1] // 2
#         image_numpy = image_numpy[:, mid_slice, :, :] # -> (C, H, W)
        
#     # å•é€šé“ -> RGB (å¤åˆ¶é€šé“)
#     if image_numpy.shape[0] == 1:
#         image_numpy = np.tile(image_numpy, (3, 1, 1))
        
#     # åå½’ä¸€åŒ– (-1, 1) -> (0, 255)
#     image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0
#     image_numpy = np.clip(image_numpy, 0, 255).astype(imtype)
    
#     return image_numpy

# def calculate_psnr(img1, img2):
#     mse = np.mean((img1.astype(np.float32) - img2.astype(np.float32)) ** 2)
#     if mse == 0: return 100
#     return 20 * np.log10(255.0 / np.sqrt(mse))

# # =========================================================================
# # [æ ¸å¿ƒåŠŸèƒ½] ç»˜åˆ¶è®ºæ–‡çº§ç›‘æ§å›¾
# # =========================================================================
# def save_paper_style_fig(save_path, epoch, exp_name, psnr_val, img_lq, img_fake, img_sq):
#     """
#     ç»˜åˆ¶ Input / Generated / Truth å¯¹æ¯”å›¾
#     """
#     fig, axes = plt.subplots(1, 3, figsize=(18, 6.5))
    
#     header_txt = f"Exp: {exp_name}  |  Epoch: {epoch}  |  Slice PSNR: {psnr_val:.2f} dB"
#     fig.suptitle(header_txt, fontsize=20, fontweight='bold', y=0.92)
    
#     items = [
#         ('Input (Low Quality)', img_lq),
#         ('Generated (High Quality)', img_fake),
#         ('Ground Truth (High Quality)', img_sq)
#     ]
    
#     for ax, (title, img) in zip(axes, items):
#         ax.imshow(img)
#         ax.set_title(title, fontsize=16, pad=10, fontweight='medium')
#         ax.axis('off') 
    
#     plt.subplots_adjust(top=0.85, wspace=0.05, left=0.02, right=0.98, bottom=0.02)
#     plt.savefig(save_path, dpi=150, bbox_inches='tight')
#     plt.close(fig)

# # =========================================================================
# # ä¸»è®­ç»ƒé€»è¾‘
# # =========================================================================
# if __name__ == '__main__':
#     opt = TrainOptions().parse()
    
#     print("\n" + "="*80)
#     print(f"ğŸš€ è®­ç»ƒå¯åŠ¨ | å®éªŒ: {opt.name}")
#     print(f"ğŸ“‚ æ•°æ®è·¯å¾„: {opt.dataroot}")
#     print("="*80 + "\n")

#     dataset = create_dataset(opt)
#     dataset_size = len(dataset) * opt.batch_size 
    
#     model = create_model(opt)
#     model.setup(opt)
    
#     expr_dir = os.path.join(opt.checkpoints_dir, opt.name)
#     if not os.path.exists(expr_dir): os.makedirs(expr_dir)
#     log_name = os.path.join(expr_dir, 'loss_log.csv')
#     loss_names = model.loss_names 
    
#     if not opt.continue_train or not os.path.exists(log_name):
#         with open(log_name, mode='w', newline='') as f:
#             header = ['Epoch', 'Time(s)'] + loss_names + ['PSNR', 'LR']
#             csv.writer(f).writerow(header)

#     total_iters = 0                 
#     for epoch in range(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + 1):
#         epoch_start_time = time.time()
        
#         epoch_loss_sum = {name: 0.0 for name in loss_names}
#         epoch_psnr_sum = 0.0
#         num_batches = 0

#         # è¿›åº¦æ¡
#         pbar = tqdm(enumerate(dataset), total=len(dataset), desc=f"Epoch {epoch}", file=sys.stdout)

#         for i, data in pbar:
#             iter_start_time = time.time()
#             total_iters += opt.batch_size
            
#             model.set_input(data)
#             model.optimize_parameters()
            
#             # Loss è®°å½•
#             errors = model.get_current_losses()
#             for k, v in errors.items():
#                 if k in epoch_loss_sum: epoch_loss_sum[k] += v

#             # [æ ¸å¿ƒä¿®å¤] æå– Tensor ç”¨äºè®¡ç®—å’Œæ˜¾ç¤º (é€‚é…æ–°ç‰ˆ AuganModel å˜é‡å)
#             # ä¼˜å…ˆè·å– fake_sq (5D), real_sq (5D), input_lq (5D)
#             fake_tensor = getattr(model, 'fake_sq', None)
#             real_tensor = getattr(model, 'real_sq', None)
#             input_tensor = getattr(model, 'input_lq', None)
            
#             # å¦‚æœæ‰¾ä¸åˆ° (æ¯”å¦‚æµ‹è¯•æ¨¡å¼æˆ–è€…å˜é‡åå˜äº†)ï¼Œå°è¯•å›é€€åˆ°æ—§åç§° (è™½ç„¶ç°åœ¨åº”è¯¥éƒ½ç»Ÿä¸€äº†)
#             if fake_tensor is None: fake_tensor = getattr(model, 'fake_B', None)
#             if real_tensor is None: real_tensor = getattr(model, 'real_B', None)
#             if input_tensor is None: input_tensor = getattr(model, 'input_A', None)
            
#             # è®¡ç®— PSNR (Logç”¨)
#             current_psnr = 0.0
#             if fake_tensor is not None and real_tensor is not None:
#                 fake_im_raw = tensor2im_custom(fake_tensor)
#                 real_im_raw = tensor2im_custom(real_tensor)
#                 current_psnr = calculate_psnr(fake_im_raw, real_im_raw)
#                 epoch_psnr_sum += current_psnr

#             num_batches += 1

#             # è¿›åº¦æ¡æ˜¾ç¤º
#             pbar.set_postfix({
#                 'L1': f"{errors.get('G_L1', errors.get('G_Pixel', 0)):.3f}", # å…¼å®¹ G_L1 å’Œ G_Pixel
#                 'PSNR': f"{current_psnr:.1f}"
#             })

#             # å®šæœŸä¿å­˜æ¨¡å‹
#             if total_iters % opt.save_latest_freq == 0:
#                 model.save_networks('latest')

#         # === Epoch ç»“æŸç»“ç®— ===
#         if num_batches > 0:
#             for k in epoch_loss_sum: epoch_loss_sum[k] /= num_batches
#             avg_psnr = epoch_psnr_sum / num_batches
#         else:
#             avg_psnr = 0.0
        
#         time_taken = time.time() - epoch_start_time
#         model.update_learning_rate()
#         current_lr = model.optimizers[0].param_groups[0]['lr']

#         # 1. æ‰“å°ä»ªè¡¨ç›˜ Log
#         gen_losses = []
#         disc_losses = []
#         for k, v in epoch_loss_sum.items():
#             if k.startswith('G_'):
#                 gen_losses.append(f"{k.replace('G_', '')}: {v:.4f}")
#             elif k.startswith('D_'):
#                 disc_losses.append(f"{k.replace('D_', '')}: {v:.4f}")

#         log_msg = (
#             f"\n{'='*20} Epoch {epoch} Summary {'='*20}\n"
#             f"  ğŸ¨ [Generator Avg] |  {'  |  '.join(gen_losses)}\n"
#             f"  âš–ï¸  [Discriminator] |  {'  |  '.join(disc_losses)}\n"
#             f"  ğŸ“Š [Metrics Avg]   |  PSNR: {avg_psnr:.2f} dB  |  Time: {time_taken:.1f}s  |  LR: {current_lr:.6f}\n"
#             f"{'-'*60}\n"
#         )
#         print(log_msg)

#         # 2. å†™å…¥ CSV
#         with open(log_name, mode='a', newline='') as f:
#             row = [epoch, f"{time_taken:.1f}"]
#             for name in loss_names:
#                 row.append(f"{epoch_loss_sum.get(name, 0.0):.4f}") # ä½¿ç”¨ .get é˜²æ­¢ Key ç¼ºå¤±æŠ¥é”™
#             row.append(f"{avg_psnr:.2f}")
#             row.append(f"{current_lr:.6f}")
#             csv.writer(f).writerow(row)

#         # 3. ç”Ÿæˆ Paper Style å¯¹æ¯”å›¾
#         if input_tensor is not None and fake_tensor is not None and real_tensor is not None:
#             img_dir = os.path.join(expr_dir, 'web_images')
#             if not os.path.exists(img_dir): os.makedirs(img_dir)
            
#             # è½¬æ¢å½“å‰è¿™å¼ å›¾çš„ Numpy æ•°æ®
#             img_lq = tensor2im_custom(input_tensor)
#             img_fake = tensor2im_custom(fake_tensor)
#             img_sq = tensor2im_custom(real_tensor)
            
#             # è®¡ç®—è¿™å¼ å±•ç¤ºå›¾ç‰‡çš„å…·ä½“ PSNR
#             slice_psnr = calculate_psnr(img_fake, img_sq)
            
#             # ç»˜åˆ¶å¤§å›¾
#             save_path = os.path.join(img_dir, f'epoch_{epoch:03d}_comparison.png')
#             save_paper_style_fig(save_path, epoch, opt.name, slice_psnr, img_lq, img_fake, img_sq)

#         # 4. ä¿å­˜æ¨¡å‹
#         if epoch % opt.save_epoch_freq == 0:
#             model.save_networks('latest')
#             model.save_networks(epoch)

#     print("ğŸ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")